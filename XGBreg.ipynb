{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "import xgboost as xgb  \n",
    "from sklearn.metrics import mean_squared_error, r2_score  \n",
    "import numpy as np  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract repository name from URL  \n",
    "def extract_repo_name(url):  \n",
    "    try:  \n",
    "        return url.split('/')[-2] + '/' + url.split('/')[-1]  \n",
    "    except:  \n",
    "        return None  \n",
    "  \n",
    "# Load the training dataset  \n",
    "training_data_path = r'D:\\0000Pond\\funding comp\\enriched_dataset\\enriched_orig_dataset.csv'  \n",
    "dataset_aug = pd.read_csv(training_data_path)  \n",
    "  \n",
    "# Load the test dataset  \n",
    "test_data_path = r'D:\\0000Pond\\funding comp\\enriched_dataset\\enriched_test.csv'  \n",
    "test_data = pd.read_csv(test_data_path)  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in training dataset:\n",
      "id                              0\n",
      "project_a                       0\n",
      "project_b                       0\n",
      "weight_a                        0\n",
      "weight_b                        0\n",
      "                               ..\n",
      "log_watchers_b_project_b        0\n",
      "log_forks_b_project_b           0\n",
      "log_commit_count_b_project_b    0\n",
      "repo_name_a                     0\n",
      "repo_name_b                     0\n",
      "Length: 112, dtype: int64\n",
      "\n",
      "NaN values in test dataset:\n",
      "id                              0\n",
      "project_a                       0\n",
      "project_b                       0\n",
      "total_amount_usd                0\n",
      "funder                          0\n",
      "                               ..\n",
      "log_watchers_b_project_b        0\n",
      "log_forks_b_project_b           0\n",
      "log_commit_count_b_project_b    0\n",
      "repo_name_a                     0\n",
      "repo_name_b                     0\n",
      "Length: 110, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract repository names for both datasets  \n",
    "dataset_aug['repo_name_a'] = dataset_aug['project_a'].apply(extract_repo_name)  \n",
    "dataset_aug['repo_name_b'] = dataset_aug['project_b'].apply(extract_repo_name)  \n",
    "test_data['repo_name_a'] = test_data['project_a'].apply(extract_repo_name)  \n",
    "test_data['repo_name_b'] = test_data['project_b'].apply(extract_repo_name)  \n",
    "  \n",
    "# Check for NaN values in the training and test datasets  \n",
    "print(\"NaN values in training dataset:\")  \n",
    "print(dataset_aug.isnull().sum())  \n",
    "print(\"\\nNaN values in test dataset:\")  \n",
    "print(test_data.isnull().sum())  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique 'funder' values from the test dataset  \n",
    "test_funders = test_data['funder'].unique()  \n",
    "  \n",
    "# Filter the training dataset to only include rows where 'funder' is in the test dataset  \n",
    "dataset_aug = dataset_aug[dataset_aug['funder'].isin(test_funders)]  \n",
    "  \n",
    "# Calculate logarithmic features for 'size' if they don't exist  \n",
    "if 'log_size_project_a' not in dataset_aug.columns:  \n",
    "    dataset_aug['log_size_project_a'] = np.log1p(dataset_aug['size_project_a'])  \n",
    "if 'log_size_project_b' not in dataset_aug.columns:  \n",
    "    dataset_aug['log_size_project_b'] = np.log1p(dataset_aug['size_project_b'])  \n",
    "if 'subscribers_count_project_a' not in dataset_aug.columns:  \n",
    "    dataset_aug['log_subscribers_count_project_a'] = np.log1p(dataset_aug['subscribers_count_project_a'])  \n",
    "if 'subscribers_count_project_b' not in dataset_aug.columns:  \n",
    "    dataset_aug['log_subscribers_count_project_b'] = np.log1p(dataset_aug['subscribers_count_project_b'])\n",
    "  \n",
    "if 'log_size_project_a' not in test_data.columns:  \n",
    "    test_data['log_size_project_a'] = np.log1p(test_data['size_project_a'])  \n",
    "if 'log_size_project_b' not in test_data.columns:  \n",
    "    test_data['log_size_project_b'] = np.log1p(test_data['size_project_b'])  \n",
    "if 'log_subscribers_count_project_a' not in test_data.columns:  \n",
    "    test_data['log_subscribers_count_project_a'] = np.log1p(test_data['subscribers_count_project_a'])  \n",
    "if 'log_subscribers_count_project_b' not in test_data.columns:  \n",
    "    test_data['log_subscribers_count_project_b'] = np.log1p(test_data['subscribers_count_project_b']) \n",
    "\n",
    "\n",
    "# Select features and target variable  \n",
    "features = [  \n",
    "    'total_amount_usd',  \n",
    "    'is_private_project_a', 'has_homepage_project_a',  \n",
    "    'log_size_project_a', 'stars_project_a', 'watchers_project_a',  \n",
    "    'has_projects_project_a', 'has_pages_project_a', 'has_wiki_project_a',  \n",
    "    'has_discussions_project_a', 'forks_project_a', 'is_archived_project_a',  \n",
    "    'is_disabled_project_a', 'open_issues_project_a', 'subscribers_count_project_a',  \n",
    "    'age_days_project_a', 'days_since_update_project_a', 'stars_ratio_project_a',  \n",
    "    'watchers_ratio_project_a', 'forks_ratio_project_a', 'size_ratio_project_a',  \n",
    "    'log_stars_project_a',  \n",
    "    'log_watchers_project_a', 'log_forks_project_a', 'log_commit_count_project_a',  \n",
    "    'log_stars_b_project_a', 'log_watchers_b_project_a', 'log_forks_b_project_a',  \n",
    "    'log_commit_count_b_project_a', 'is_private_project_b', 'has_homepage_project_b',  \n",
    "    'log_size_project_b', 'stars_project_b', 'watchers_project_b',  \n",
    "    'has_projects_project_b', 'has_pages_project_b', 'has_wiki_project_b',  \n",
    "    'has_discussions_project_b', 'forks_project_b', 'is_archived_project_b',  \n",
    "    'is_disabled_project_b', 'open_issues_project_b', 'subscribers_count_project_b',  \n",
    "    'age_days_project_b', 'days_since_update_project_b', 'stars_ratio_project_b',  \n",
    "    'watchers_ratio_project_b', 'forks_ratio_project_b', 'size_ratio_project_b',  \n",
    "    'log_stars_project_b',  \n",
    "    'log_watchers_project_b', 'log_forks_project_b', 'log_commit_count_project_b',  \n",
    "    'log_stars_b_project_b', 'log_watchers_b_project_b', 'log_forks_b_project_b',  \n",
    "    'log_commit_count_b_project_b',  \n",
    "    'repo_name_a', 'repo_name_b'  \n",
    "]  \n",
    "  \n",
    "# Remove plain count features if logarithmic features are present  \n",
    "log_features = [  \n",
    "    'log_subscribers_count_project_a','log_subscribers_count_project_b',\n",
    "    'log_size_project_a', 'log_stars_project_a', 'log_watchers_project_a', 'log_forks_project_a', 'log_commit_count_project_a',  \n",
    "    'log_stars_b_project_a', 'log_watchers_b_project_a', 'log_forks_b_project_a', 'log_commit_count_b_project_a',  \n",
    "    'log_size_project_b', 'log_stars_project_b', 'log_watchers_project_b', 'log_forks_project_b', 'log_commit_count_project_b',  \n",
    "    'log_stars_b_project_b', 'log_watchers_b_project_b', 'log_forks_b_project_b', 'log_commit_count_b_project_b'  \n",
    "]  \n",
    "  \n",
    "plain_features = [  \n",
    "    'size_project_a', 'stars_project_a', 'watchers_project_a', 'forks_project_a', 'commit_count_project_a',  \n",
    "    'stars_b_project_a', 'watchers_b_project_a', 'forks_b_project_a', 'commit_count_b_project_a',  \n",
    "    'size_project_b', 'stars_project_b', 'watchers_project_b', 'forks_project_b', 'commit_count_project_b',  \n",
    "    'stars_b_project_b', 'watchers_b_project_b', 'forks_b_project_b', 'commit_count_b_project_b',\n",
    "    'subscribers_count_project_b', 'subscribers_count_project_a'\n",
    "\n",
    "]  \n",
    "  \n",
    "# Remove plain features if log features are present  \n",
    "features = [col for col in features if col not in plain_features or col in log_features]  \n",
    "  \n",
    "# Target variable  \n",
    "target = 'weight_a'  \n",
    "  \n",
    "# Encode categorical variables  \n",
    "label_encoders = {}  \n",
    "for col in ['funder', 'quarter', 'repo_name_a', 'repo_name_b']:  \n",
    "    if col in dataset_aug.columns:  \n",
    "        le = LabelEncoder()  \n",
    "        dataset_aug[col] = le.fit_transform(dataset_aug[col])  \n",
    "        label_encoders[col] = le  \n",
    "  \n",
    "    if col in test_data.columns:  \n",
    "        # Use transform with error handling for unseen labels  \n",
    "        try:  \n",
    "            test_data[col] = le.transform(test_data[col])  \n",
    "        except ValueError:  \n",
    "            # Assign a default value for unseen labels  \n",
    "            test_data[col] = -1  \n",
    "  \n",
    "# Convert boolean columns to integer  \n",
    "boolean_cols = [  \n",
    "    'is_private_project_a', 'has_homepage_project_a', 'has_projects_project_a',  \n",
    "    'has_pages_project_a', 'has_wiki_project_a', 'has_discussions_project_a',  \n",
    "    'is_archived_project_a', 'is_disabled_project_a',  \n",
    "    'is_private_project_b', 'has_homepage_project_b', 'has_projects_project_b',  \n",
    "    'has_pages_project_b', 'has_wiki_project_b', 'has_discussions_project_b',  \n",
    "    'is_archived_project_b', 'is_disabled_project_b'  \n",
    "]  \n",
    "  \n",
    "for col in boolean_cols:  \n",
    "    if col in dataset_aug.columns:  \n",
    "        dataset_aug[col] = dataset_aug[col].astype(int)  \n",
    "    if col in test_data.columns:  \n",
    "        test_data[col] = test_data[col].astype(int)  \n",
    "  \n",
    "# Filter out features that are not present in the dataset  \n",
    "features = [col for col in features if col in dataset_aug.columns and col in test_data.columns]  \n",
    "  \n",
    "# Select features and target  \n",
    "X = dataset_aug[features]  \n",
    "y = dataset_aug[target]  \n",
    "  \n",
    "# Split the data into training and testing sets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.030235349514398293\n",
      "R^2 Score: 0.7973704063690457\n",
      "Predictions saved to /kaggle/working/predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize the XGBoost regressor  \n",
    "xgb_regressor = xgb.XGBRegressor(  \n",
    "    objective='reg:squarederror',  \n",
    "    n_estimators=200,  \n",
    "    learning_rate=0.1,  \n",
    "    max_depth=8,  \n",
    "    subsample=0.8,  \n",
    "    colsample_bytree=0.2,  \n",
    "    random_state=42  \n",
    ")  \n",
    "  \n",
    "# Train the model  \n",
    "xgb_regressor.fit(X_train, y_train)  \n",
    "  \n",
    "# Make predictions  \n",
    "y_pred = xgb_regressor.predict(X_test)  \n",
    "  \n",
    "# Ensure predictions are within the range [0, 1]  \n",
    "y_pred = y_pred.clip(min=0, max=1)  \n",
    "  \n",
    "# Calculate evaluation metrics  \n",
    "mse = mean_squared_error(y_test, y_pred)  \n",
    "r2 = r2_score(y_test, y_pred)  \n",
    "  \n",
    "print(f\"Mean Squared Error: {mse}\")  \n",
    "print(f\"R^2 Score: {r2}\")  \n",
    "  \n",
    "# Ensure all necessary features are present in the test dataset  \n",
    "# If a feature is not present, you can either add it with a default value or remove it from the feature list  \n",
    "# Here, we will remove features that are not present in the test dataset  \n",
    "test_features = [col for col in features if col in test_data.columns]  \n",
    "  \n",
    "# Select features for test data  \n",
    "X_test_final = test_data[test_features]  \n",
    "  \n",
    "# Make predictions on the test dataset  \n",
    "y_pred_test = xgb_regressor.predict(X_test_final)  \n",
    "  \n",
    "# Ensure predictions are within the range [0, 1]  \n",
    "y_pred_test = y_pred_test.clip(min=0, max=1)  \n",
    "  \n",
    "# Calculate weight_b as 1 - weight_a  \n",
    "y_pred_test_b = 1 - y_pred_test  \n",
    "  \n",
    "# Create a DataFrame for the predictions  \n",
    "predictions_df = pd.DataFrame({  \n",
    "    'id': test_data['id'],  \n",
    "    'pred': y_pred_test \n",
    "})  \n",
    "  \n",
    "# Save the predictions to a CSV file  \n",
    "predictions_df.to_csv('D:/0000Pond/funding comp/submission_csv/xgb_enr_aug_funderfilter_logfeat_n100_col0,2_.csv', index=False)  \n",
    "  \n",
    "print(\"Predictions saved to /kaggle/working/predictions.csv\")  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dlib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "import xgboost as xgb  \n",
    "from sklearn.metrics import mean_squared_error, r2_score  \n",
    "import numpy as np  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract repository name from URL  \n",
    "def extract_repo_name(url):  \n",
    "    try:  \n",
    "        return url.split('/')[-2] + '/' + url.split('/')[-1]  \n",
    "    except:  \n",
    "        return None  \n",
    "  \n",
    "# Load the training dataset  \n",
    "training_data_path = r'D:\\0000Pond\\funding comp\\enriched_dataset\\enriched_aug_dataset.csv'  \n",
    "dataset_aug = pd.read_csv(training_data_path)  \n",
    "  \n",
    "# Load the test dataset  \n",
    "test_data_path = r'D:\\0000Pond\\funding comp\\enriched_dataset\\enriched_test.csv'  \n",
    "test_data = pd.read_csv(test_data_path)  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in training dataset:\n",
      "id                              0\n",
      "project_a                       0\n",
      "project_b                       0\n",
      "weight_a                        0\n",
      "weight_b                        0\n",
      "                               ..\n",
      "log_watchers_b_project_b        0\n",
      "log_forks_b_project_b           0\n",
      "log_commit_count_b_project_b    0\n",
      "repo_name_a                     0\n",
      "repo_name_b                     0\n",
      "Length: 112, dtype: int64\n",
      "\n",
      "NaN values in test dataset:\n",
      "id                              0\n",
      "project_a                       0\n",
      "project_b                       0\n",
      "total_amount_usd                0\n",
      "funder                          0\n",
      "                               ..\n",
      "log_watchers_b_project_b        0\n",
      "log_forks_b_project_b           0\n",
      "log_commit_count_b_project_b    0\n",
      "repo_name_a                     0\n",
      "repo_name_b                     0\n",
      "Length: 110, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract repository names for both datasets  \n",
    "dataset_aug['repo_name_a'] = dataset_aug['project_a'].apply(extract_repo_name)  \n",
    "dataset_aug['repo_name_b'] = dataset_aug['project_b'].apply(extract_repo_name)  \n",
    "test_data['repo_name_a'] = test_data['project_a'].apply(extract_repo_name)  \n",
    "test_data['repo_name_b'] = test_data['project_b'].apply(extract_repo_name)  \n",
    "  \n",
    "# Check for NaN values in the training and test datasets  \n",
    "print(\"NaN values in training dataset:\")  \n",
    "print(dataset_aug.isnull().sum())  \n",
    "print(\"\\nNaN values in test dataset:\")  \n",
    "print(test_data.isnull().sum())  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique 'funder' values from the test dataset  \n",
    "test_funders = test_data['funder'].unique()  \n",
    "  \n",
    "# Filter the training dataset to only include rows where 'funder' is in the test dataset  \n",
    "dataset_aug = dataset_aug[dataset_aug['funder'].isin(test_funders)]  \n",
    "  \n",
    "# Calculate logarithmic features for 'size' if they don't exist  \n",
    "if 'log_size_project_a' not in dataset_aug.columns:  \n",
    "    dataset_aug['log_size_project_a'] = np.log1p(dataset_aug['size_project_a'])  \n",
    "if 'log_size_project_b' not in dataset_aug.columns:  \n",
    "    dataset_aug['log_size_project_b'] = np.log1p(dataset_aug['size_project_b'])  \n",
    "if 'subscribers_count_project_a' not in dataset_aug.columns:  \n",
    "    dataset_aug['log_subscribers_count_project_a'] = np.log1p(dataset_aug['subscribers_count_project_a'])  \n",
    "if 'subscribers_count_project_b' not in dataset_aug.columns:  \n",
    "    dataset_aug['log_subscribers_count_project_b'] = np.log1p(dataset_aug['subscribers_count_project_b'])\n",
    "  \n",
    "if 'log_size_project_a' not in test_data.columns:  \n",
    "    test_data['log_size_project_a'] = np.log1p(test_data['size_project_a'])  \n",
    "if 'log_size_project_b' not in test_data.columns:  \n",
    "    test_data['log_size_project_b'] = np.log1p(test_data['size_project_b'])  \n",
    "if 'log_subscribers_count_project_a' not in test_data.columns:  \n",
    "    test_data['log_subscribers_count_project_a'] = np.log1p(test_data['subscribers_count_project_a'])  \n",
    "if 'log_subscribers_count_project_b' not in test_data.columns:  \n",
    "    test_data['log_subscribers_count_project_b'] = np.log1p(test_data['subscribers_count_project_b']) \n",
    "\n",
    "\n",
    "# Select features and target variable  \n",
    "features = [  \n",
    "    'total_amount_usd',  \n",
    "    'is_private_project_a', 'has_homepage_project_a',  \n",
    "    'log_size_project_a', 'stars_project_a', 'watchers_project_a',  \n",
    "    'has_projects_project_a', 'has_pages_project_a', 'has_wiki_project_a',  \n",
    "    'has_discussions_project_a', 'forks_project_a', 'is_archived_project_a',  \n",
    "    'is_disabled_project_a', 'open_issues_project_a', 'subscribers_count_project_a',  \n",
    "    'age_days_project_a', 'days_since_update_project_a', 'stars_ratio_project_a',  \n",
    "    'watchers_ratio_project_a', 'forks_ratio_project_a', 'size_ratio_project_a',  \n",
    "    'log_stars_project_a',  \n",
    "    'log_watchers_project_a', 'log_forks_project_a', 'log_commit_count_project_a',  \n",
    "    'log_stars_b_project_a', 'log_watchers_b_project_a', 'log_forks_b_project_a',  \n",
    "    'log_commit_count_b_project_a', 'is_private_project_b', 'has_homepage_project_b',  \n",
    "    'log_size_project_b', 'stars_project_b', 'watchers_project_b',  \n",
    "    'has_projects_project_b', 'has_pages_project_b', 'has_wiki_project_b',  \n",
    "    'has_discussions_project_b', 'forks_project_b', 'is_archived_project_b',  \n",
    "    'is_disabled_project_b', 'open_issues_project_b', 'subscribers_count_project_b',  \n",
    "    'age_days_project_b', 'days_since_update_project_b', 'stars_ratio_project_b',  \n",
    "    'watchers_ratio_project_b', 'forks_ratio_project_b', 'size_ratio_project_b',  \n",
    "    'log_stars_project_b',  \n",
    "    'log_watchers_project_b', 'log_forks_project_b', 'log_commit_count_project_b',  \n",
    "    'log_stars_b_project_b', 'log_watchers_b_project_b', 'log_forks_b_project_b',  \n",
    "    'log_commit_count_b_project_b',  \n",
    "    'repo_name_a', 'repo_name_b'  \n",
    "]  \n",
    "  \n",
    "# Remove plain count features if logarithmic features are present  \n",
    "log_features = [  \n",
    "    'log_subscribers_count_project_a','log_subscribers_count_project_b',\n",
    "    'log_size_project_a', 'log_stars_project_a', 'log_watchers_project_a', 'log_forks_project_a', 'log_commit_count_project_a',  \n",
    "    'log_stars_b_project_a', 'log_watchers_b_project_a', 'log_forks_b_project_a', 'log_commit_count_b_project_a',  \n",
    "    'log_size_project_b', 'log_stars_project_b', 'log_watchers_project_b', 'log_forks_project_b', 'log_commit_count_project_b',  \n",
    "    'log_stars_b_project_b', 'log_watchers_b_project_b', 'log_forks_b_project_b', 'log_commit_count_b_project_b'  \n",
    "]  \n",
    "  \n",
    "plain_features = [  \n",
    "    'size_project_a', 'stars_project_a', 'watchers_project_a', 'forks_project_a', 'commit_count_project_a',  \n",
    "    'stars_b_project_a', 'watchers_b_project_a', 'forks_b_project_a', 'commit_count_b_project_a',  \n",
    "    'size_project_b', 'stars_project_b', 'watchers_project_b', 'forks_project_b', 'commit_count_project_b',  \n",
    "    'stars_b_project_b', 'watchers_b_project_b', 'forks_b_project_b', 'commit_count_b_project_b',\n",
    "    'subscribers_count_project_b', 'subscribers_count_project_a'\n",
    "\n",
    "]  \n",
    "  \n",
    "# Remove plain features if log features are present  \n",
    "features = [col for col in features if col not in plain_features or col in log_features]  \n",
    "  \n",
    "# Target variable  \n",
    "target = 'weight_a'  \n",
    "  \n",
    "# Encode categorical variables  \n",
    "label_encoders = {}  \n",
    "for col in ['funder', 'quarter', 'repo_name_a', 'repo_name_b']:  \n",
    "    if col in dataset_aug.columns:  \n",
    "        le = LabelEncoder()  \n",
    "        dataset_aug[col] = le.fit_transform(dataset_aug[col])  \n",
    "        label_encoders[col] = le  \n",
    "  \n",
    "    if col in test_data.columns:  \n",
    "        # Use transform with error handling for unseen labels  \n",
    "        try:  \n",
    "            test_data[col] = le.transform(test_data[col])  \n",
    "        except ValueError:  \n",
    "            # Assign a default value for unseen labels  \n",
    "            test_data[col] = -1  \n",
    "  \n",
    "# Convert boolean columns to integer  \n",
    "boolean_cols = [  \n",
    "    'is_private_project_a', 'has_homepage_project_a', 'has_projects_project_a',  \n",
    "    'has_pages_project_a', 'has_wiki_project_a', 'has_discussions_project_a',  \n",
    "    'is_archived_project_a', 'is_disabled_project_a',  \n",
    "    'is_private_project_b', 'has_homepage_project_b', 'has_projects_project_b',  \n",
    "    'has_pages_project_b', 'has_wiki_project_b', 'has_discussions_project_b',  \n",
    "    'is_archived_project_b', 'is_disabled_project_b'  \n",
    "]  \n",
    "  \n",
    "for col in boolean_cols:  \n",
    "    if col in dataset_aug.columns:  \n",
    "        dataset_aug[col] = dataset_aug[col].astype(int)  \n",
    "    if col in test_data.columns:  \n",
    "        test_data[col] = test_data[col].astype(int)  \n",
    "  \n",
    "# Filter out features that are not present in the dataset  \n",
    "features = [col for col in features if col in dataset_aug.columns and col in test_data.columns]  \n",
    "\n",
    "# Select features and target  \n",
    "X = dataset_aug[features]  \n",
    "y = dataset_aug[target]  \n",
    "  \n",
    "# Split the data into training and testing sets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.03022538089943096\n",
      "R^2 Score: 0.8121208213357709\n",
      "Predictions saved to D:/0000Pond/funding comp/submission_csv/pond_xgb_enr_aug_funderfilter_logfeat_n100_col02.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the XGBoost regressor  \n",
    "xgb_regressor = xgb.XGBRegressor(  \n",
    "    objective='reg:squarederror',  \n",
    "    n_estimators=100,  \n",
    "    learning_rate=0.1,  \n",
    "    max_depth=8,  \n",
    "    subsample=0.8,  \n",
    "    colsample_bytree=0.2,  \n",
    "    random_state=42  \n",
    ")  \n",
    "  \n",
    "# Train the model  \n",
    "xgb_regressor.fit(X_train, y_train)  \n",
    "  \n",
    "# Make predictions  \n",
    "y_pred = xgb_regressor.predict(X_test)  \n",
    "  \n",
    "# Ensure predictions are within the range [0, 1]  \n",
    "y_pred = y_pred.clip(min=0, max=1)  \n",
    "  \n",
    "# Calculate evaluation metrics  \n",
    "mse = mean_squared_error(y_test, y_pred)  \n",
    "r2 = r2_score(y_test, y_pred)  \n",
    "  \n",
    "print(f\"Mean Squared Error: {mse}\")  \n",
    "print(f\"R^2 Score: {r2}\")  \n",
    "  \n",
    "# Ensure all necessary features are present in the test dataset  \n",
    "# If a feature is not present, you can either add it with a default value or remove it from the feature list  \n",
    "# Here, we will remove features that are not present in the test dataset  \n",
    "test_features = [col for col in features if col in test_data.columns]  \n",
    "  \n",
    "# Select features for test data  \n",
    "X_test_final = test_data[test_features]  \n",
    "  \n",
    "# Make predictions on the test dataset  \n",
    "y_pred_test = xgb_regressor.predict(X_test_final)  \n",
    "  \n",
    "# Ensure predictions are within the range [0, 1]  \n",
    "y_pred_test = y_pred_test.clip(min=0, max=1)  \n",
    "  \n",
    "# Calculate weight_b as 1 - weight_a  \n",
    "y_pred_test_b = 1 - y_pred_test  \n",
    "  \n",
    "# Create a DataFrame for the predictions  \n",
    "predictions_df = pd.DataFrame({  \n",
    "    'id': test_data['id'],  \n",
    "    'pred': y_pred_test \n",
    "})  \n",
    "  \n",
    "# Save the predictions to a CSV file  \n",
    "save_path = 'D:/0000Pond/funding comp/submission_csv/'\n",
    "filename = 'pond_xgb_enr_aug_funderfilter_logfeat_n100_col02.csv'\n",
    "predictions_df.to_csv(save_path+filename, index=False)  \n",
    "  \n",
    "print(\"Predictions saved to\",save_path+filename)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id      pred\n",
      "0   20884  0.160022\n",
      "1   20885  0.484619\n",
      "2   20886  0.579444\n",
      "3   20887  0.943566\n",
      "4   20888  0.386261\n",
      "5   20889  0.432100\n",
      "6   20890  0.430499\n",
      "7   20891  0.550144\n",
      "8   20892  0.296190\n",
      "9   20893  0.732867\n",
      "10  20894  0.664330\n",
      "11  20895  0.339684\n",
      "12  20896  0.554359\n",
      "13  20897  0.547065\n",
      "14  20898  0.720543\n",
      "15  20899  0.694483\n",
      "16  20900  0.801367\n",
      "17  20901  0.621893\n",
      "18  20902  0.536369\n",
      "19  20903  0.904986\n",
      "20  20904  0.778745\n",
      "21  20905  0.135827\n",
      "22  20906  0.207806\n",
      "23  20907  0.417224\n",
      "24  20908  0.524013\n",
      "25  20909  0.573763\n",
      "26  20910  0.274732\n",
      "27  20911  0.455478\n",
      "28  20912  0.702933\n",
      "29  20913  0.463720\n",
      "30  20914  0.435110\n",
      "31  20915  0.601142\n",
      "32  20916  0.821220\n",
      "33  20917  0.920835\n",
      "34  20918  0.754515\n",
      "35  20919  0.438765\n",
      "36  20920  0.597449\n",
      "37  20921  0.383764\n",
      "38  20922  0.620282\n",
      "39  20923  0.783024\n"
     ]
    }
   ],
   "source": [
    "print(predictions_df.head(40))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
